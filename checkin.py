import os
import json
import time
import random
import cloudscraper
from pypushdeer import PushDeer


CHECKIN_URL = "https://glados.space"
STATUS_URL = "https://glados.space"

HEADERS_BASE = {
    "origin": "https://glados.space",
    "referer": "https://glados.space",
    "user-agent": (
        "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
        "AppleWebKit/537.36 (KHTML, like Gecko) "
        "Chrome/120.0.0.0 Safari/537.36"
    ),
    "content-type": "application/json;charset=UTF-8",
}

PAYLOAD = {"token": "glados.cloud"}
# å¢åŠ è¶…æ—¶æ—¶é—´ä»¥é€‚åº” Cloudflare éªŒè¯è¿‡ç¨‹
TIMEOUT = 30


def push(sckey: str, title: str, text: str):
    if sckey:
        PushDeer(pushkey=sckey).send_text(title, desp=text)


def safe_json(resp):
    try:
        return resp.json()
    except Exception:
        return {}


def main():
    sckey = os.getenv("SENDKEY", "")
    cookies_env = os.getenv("COOKIES", "")
    cookies = [c.strip() for c in cookies_env.split("&") if c.strip()]

    if not cookies:
        push(sckey, "GLaDOS ç­¾åˆ°", "âŒ æœªæ£€æµ‹åˆ° COOKIES")
        return

    # ä½¿ç”¨ cloudscraper åˆ›å»ºä¼šè¯
    scraper = cloudscraper.create_scraper()
    ok = fail = repeat = 0
    lines = []

    for idx, cookie in enumerate(cookies, 1):
        headers = dict(HEADERS_BASE)
        headers["cookie"] = cookie

        email = "unknown"
        points = "-"
        days = "-"

        try:
            # ä½¿ç”¨ scraper ä¼šè¯å‘é€è¯·æ±‚
            r = scraper.post(
                CHECKIN_URL,
                headers=headers,
                data=json.dumps(PAYLOAD),
                timeout=TIMEOUT,
            )

            j = safe_json(r)
            msg = j.get("message", "")
            msg_lower = msg.lower()

            if "got" in msg_lower:
                ok += 1
                points = j.get("points", "-")
                status = "âœ… æˆåŠŸ"
            elif "repeat" in msg_lower or "already" in msg_lower:
                repeat += 1
                status = "ğŸ” å·²ç­¾åˆ°"
            else:
                fail += 1
                status = "âŒ å¤±è´¥"

            # çŠ¶æ€æ¥å£ï¼ˆå…è®¸å¤±è´¥ï¼‰
            s = scraper.get(STATUS_URL, headers=headers, timeout=TIMEOUT)
            sj = safe_json(s).get("data") or {}
            email = sj.get("email", email)
            if sj.get("leftDays") is not None:
                days = f"{int(float(sj['leftDays']))} å¤©"

        except Exception as e:
            fail += 1
            status = f"âŒ å¼‚å¸¸: {e}" # æ‰“å°å…·ä½“çš„å¼‚å¸¸ä¿¡æ¯ä¾¿äºè°ƒè¯•

        lines.append(f"{idx}. {email} | {status} | P:{points} | å‰©ä½™:{days}")
        # å¢åŠ éšæœºå»¶è¿Ÿï¼Œæ¨¡æ‹Ÿäººç±»è¡Œä¸ºï¼Œå‡å°‘è¢«å°ç¦çš„é£é™©
        time.sleep(random.uniform(2, 5))

    title = f"GLaDOS ç­¾åˆ°å®Œæˆ âœ…{ok} âŒ{fail} ğŸ”{repeat}"
    content = "\n".join(lines)

    print(content)
    push(sckey, title, content)


if __name__ == "__main__":
    main()
